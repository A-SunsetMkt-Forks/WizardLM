# WizardLM: An Instruction-following LLM Using Evol-Instruct
Empowering Large Language Models to Follow Complex Instructions

<p align="center" width="100%">
<a ><img src="imgs/WizardLM.png" alt="WizardLM" style="width: 20%; min-width: 300px; display: block; margin: auto;"></a>
</p>

[![Code License](https://img.shields.io/badge/Code%20License-Apache_2.0-green.svg)](https://github.com/tatsu-lab/stanford_alpaca/blob/main/LICENSE)
[![Data License](https://img.shields.io/badge/Data%20License-CC%20By%20NC%204.0-red.svg)](https://github.com/tatsu-lab/stanford_alpaca/blob/main/DATA_LICENSE)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/)

## Overview of Evol-Instruct

Evol-Instruct is a novel method using LLMs instead of humans to automatically mass-produce open-domain instructions of various difficulty levels and skills range, to improve the performance of LLMs.

## Comparison with ChatGPT under complex instructions

## Contents
1. [News](#news)

2. [Online Demo](#online-demo)

3. [Training Data](#train_data)

4. [WizardLM Weights](#wizardlm-weights)

5. [Fine-tuning](#finetune)

6. [Inference](#inference)

7. [Evaluation](#evaluation)

8. [Citation](#citation)

## Training Data

[`wizardlm_train_70k.json`](./wizardlm_train_70k.json) contains 70K instruction-following data generated from Evol-Instruct. We used it for fine-tuning the WizardLM model.
This JSON file is a list of dictionaries, each dictionary contains the following fields:

- `instruction`: `str`, describes the task the model should perform. Each of the 70K instructions is unique.
- `output`: `str`, the answer to the instruction as generated by `gpt-3.5-turbo`.

## WizardLM Weights
We release [WizardLM] weights as delta weights to comply with the LLaMA model license.
You can add our delta to the original LLaMA weights to obtain the WizardLM weights. Instructions:

1. Get the original LLaMA weights in the huggingface format by following the instructions [here](https://huggingface.co/docs/transformers/main/model_doc/llama).
2. Please download our delta model at the following [link]() Use the following scripts to get WizardLM weights by applying our delta. They will automatically download delta weights from our Hugging Face [account](https://huggingface.co/lmsys).

**NOTE**:
Weights v1.1 are only compatible with ```transformers>=4.28.0```.

### WizardLM-7B
This conversion command needs around 30 GB of CPU RAM.
See the "Low CPU Memory Conversion" section below if you do not have enough memory.
```bash
python3 -m fastchat.model.apply_delta \
    --base-model-path /path/to/llama-7b \
    --target-model-path /output/path/to/vicuna-7b \
    --delta-path lmsys/vicuna-7b-delta-v1.1
```

## Fine-tuning

We fine-tune WizardLM using code from this [repo](https://github.com/AetherCortex/Llama-X).
We fine-tune LLaMA-7B with the following hyperparameters:

| Hyperparameter | LLaMA-7B |
|----------------|----------|
| Batch size     | 64       |
| Learning rate  | 2e-5     |
| Epochs         | 3        |
| Max length     | 2048     |
| Warmup step    | 2        |
| LR scheduler   | cosine   |

To reproduce our fine-tuning of WizardLM, please follow the following steps:
1. According to the instructions of this [repo](https://github.com/AetherCortex/Llama-X), install the environment, download the training code, and deploy.
2. Replace the train.py with the train.py in our repo(src/train.py)
3. Execute the following training command:
```bash
deepspeed train.py \
    --model_name_or_path /path/to/llama-7B/hf \
    --data_path /path/to/example_data.json \
    --output_dir /path/to/llama-7B/hf/ft \
    --num_train_epochs 3 \
    --model_max_length 512 \
    --per_device_train_batch_size 64 \
    --per_device_eval_batch_size 1 \
    --gradient_accumulation_steps 1 \
    --evaluation_strategy "no" \
    --save_strategy "steps" \
    --save_steps 100 \
    --save_total_limit 2 \
    --learning_rate 2e-5 \
    --warmup_steps 2 \
    --logging_steps 2 \
    --lr_scheduler_type "cosine" \
    --report_to "tensorboard" \
    --gradient_checkpointing True \
    --deepspeed configs/deepspeed_config.json \
    --fp16 True
```
### Evaluation

To evaluate Wizard, we conduct human evaluation on the inputs from the human instruct evaluation set. This evaluation set was collected by the authors and covers a diverse list of user-oriented instructions including email writing, social media, formula, code, table and productivity tools. We performed a blind pairwise comparison between Wizard and baselines. Specifically, we randomly sample 218 examples from test set, and recruit 10 well-educated annotators to rank the models from 1 to 5 on relevance, knowledgeable, reasoning, calculation and accuracy. 

Wizard achieved significantly better results than Alpaca and Vicuna-7b. 


<p align="center" width="60%">
<a ><img src="imgs/win.png" alt="WizardLM" style="width: 20%; min-width: 300px; display: block; margin: auto;"></a>
</p>

In the high-difficulty section of our test set (difficulty level >= 8), Wizard even outperforms ChatGPT, with a win rate 7.9% larger than Chatgpt (42.9% vs. 35.0%). This indicates that our method can significantly improve the ability of large language models to handle complex instructions.

<p align="center" width="60%">
<a ><img src="imgs/windiff.png" alt="WizardLM" style="width: 20%; min-width: 300px; display: block; margin: auto;"></a>
</p>

### Citation

Please cite the repo if you use the data or code in this repo.

```
@misc{xu2023wizardlm,
      title={WizardLM: Empowering Large Language Models to Follow Complex Instructions}, 
      author={Can Xu and Qingfeng Sun and Kai Zheng and Xiubo Geng and Pu Zhao and Jiazhan Feng and Chongyang Tao and Daxin Jiang},
      year={2023},
      eprint={2304.12244},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
```
